{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to the Biodiversity Genomic Data Management Hub! We recognise that data management for biodiversity genomic research projects can be a challenge, particularly for researchers entering this space, and you are likely to have many questions as you proceed on your journey. </p> <p>The primary goal of this Hub is to support biodiversity genomics researchers in developing good data management practices that embody the FAIR and CARE Guiding Principles.</p> <p>Good practice versus best practice</p> <p>Based on our lived experiences working on biodiversity genomics projects, we recognise there are different standards of data management. We acknowledge that achieving best practices (i.e., those described in the community guidelines and standards we strive towards implementing) is aspirational, and may not always be practicable within the constraints of a research project due to external factors (see Personas). Instead, we encourage researchers to pursue \u2018good practices\u2019 as a stepping stone on the journey towards best practices. From our collective experience, one lesson is clear\u2014that any data management is better than no data management. We strongly encourage any incremental improvements to data management by individuals, as capacity allows. Rather than lamenting past inadequacies, we encourage forward-focussed data management solutions, as described in the associated Modules.</p> <p>In this Hub we leverage our personal data management experiences to describe four user experience personas that illustrate some of the challenges associated with biodiversity genomic data management across the research ecosystem. We use these personas to demonstrate a diversity of the realistic considerations, compromises, and questions that arise from biodiversity genomic data management. </p> <p>While real life is not typically this tidy, we hope that you may see some of your own experiences reflected through a combination of these personas. You may find that you relate most strongly to one persona, but we encourage you to peruse all four personas to gain a breadth of perspectives across career stages and roles.</p> <p>Who are we?</p> <p>We are a cross-institutional, interdisciplinary, multi-career stage collaborative team based in Aotearoa New Zealand. This team includes biodiversity genomics researchers, institutional and national eResearch and libraries staff, and researchers with experience in being responsive to Indigenous considerations pertaining to culturally significant biodiversity genomic data, both as Indigenous and non-Indigenous scholars. Together we have extensive experience in overseeing biodiversity genomic research projects, curating and managing biodiversity genomic datasets including those with cultural significance, developing project-specific data management plans (DMPs), and providing data management solutions to research groups. We have lived experience with the caveats of applying data management theory to real-life research situations.</p> <p>Based on the questions that arise from these personas, we direct you to Modules that examine these challenges in more detail and provide resources and solutions to help you on your data management journey. While these modules are non-exhaustive, they will be regularly updated as new solutions come to light. </p> <p>Through this Hub, we aim to empower the biodiversity genomics community to minimise risks and maximise research impact now and into the future. We encourage researchers to view data management as a behaviour intrinsic to the research process, and to adopt a mindset of adaptability to the various hurdles you may encounter along the way.</p> <p>We welcome feedback, along with the contribution of resource suggestions and additional module topics for inclusion via the GitHub Issues page associated with the Hub.</p> <p></p> <p>Citation &amp; Licensing</p> <p>Biodiversity Genomic Data Management Hub material is licensed under the Creative Commons Attribution 4.0 International Public License (CC-BY 4.0).  This Hub is intended as a resource that sits alongside the publication Journeying towards best practice data management in biodiversity genomics. If you refer to the publication or Hub in your research or teaching, we request that you include a link to the Hub, and the citation:</p> <p>Forsdick, N. J., Wold, J. R., Angelo, A., Bissey, F., Hart, J., Head, M., Liggins, L., Senanayake, D., &amp; Steeves, T. E. (2023). Journeying towards best practice data management in biodiversity genomics. Molecular Ecology Resources. https://doi.org/10.1111/1755-0998.13880.</p> <p><p> Personas Modules </p></p>"},{"location":"glossary/","title":"Glossary","text":"Terms Definitions BAM Binary Alignment Map. A file format used to encode aligned genomic data. CARE Guiding Principles CARE Principles for Indigenous Data Governance. Designed to complement the FAIR Guiding Principles, these people- and purpose-oriented principles and supporting concepts (Collective benefit, Authority to control, Responsibility, Ethics) reflect the crucial role of data in advancing innovation, governance, and self-determination among Indigenous Peoples (Carroll et al. 2020; 2021). data life cycle The steps in the research process specifically pertaining to data, from planning, collection and generation, analysis and collaboration, evaluation, storage, dissemination, access, and reuse, which can contribute to the planning for new data generation. The data and research life cycles are distinct but interrelated. data management The processes and practices associated with the documentation and storage of and access to data and associated metadata throughout the research life cycle. DMP Data management plan. A document describing the data that will be generated during a research project, and how it will be used, accessed, and stored during the research life cycle. Also known as a data management and sharing plan, though in the definition of data management used here, data sharing is inherently included in data access. DSI Digital sequence information. eResearch The use of digital tools and techniques to advance research. eResearch and libraries staff A broad group that includes research software engineers, research infrastructure developers, data scientists, data stewards, and other professional services staff that deliver library, IT, bioinformatics, and high-performance computing support. FAIR Guiding Principles FAIR Guiding Principles for scientific data management and stewardship, aiming to improve the Findability, Accessibility, Interoperability, and Reuse of data. GPU Graphics processing unit. Often used to accelerate data processing. HDD Hard disk drive. HPC High performance computing. Indigenous data The tangible and/or intangible cultural materials, belongings, knowledge, digital data, and information about Indigenous Peoples or that to which they relate. Indigenous data sovereignty The expression of a legitimate right of Indigenous Peoples to control the access, the collection, ownership, application and governance of their own data, knowledge, and/or information that derives from unique cultural histories, expressions, practices, and contexts (https://localcontexts.org/indigenous-data-sovereignty/). kaitiakitanga guardianship, protection (te reo M\u0101ori). metadata Data that provides information about other data. For biodiversity genomic data, metadata can provide information regarding context (e.g., taxonomic, spatial, temporal, and associated permissions) as well as used technologies/methodologies. MIGS Minimum Information about a Genome Sequence. MIxS Minimum Information about any (X) Sequence. NCBI National Centre for Biotechnology Information. Part of the United States National Library of Medicine, and host of various genomic databases such as GenBank and the Sequence Read Archive. Open data Data anyone can use and share, typically publicly accessible and with an open licence. research life cycle The steps in the process of scientific research from inception (research planning, design, and funding) to completion (dissemination of results and real-world impact), which often leads back to development of new related projects. The research and data life cycles are distinct but interrelated. SRA NCBI's Sequence Read Archive, the largest global repository of genomic data. SSD Solid state drive. VM Virtual machine. A software-based computer system emulating that of a different physical machine. VMs are often used to run a different operating system than that of the primary system of the physical computer."},{"location":"modules/","title":"Module overview","text":"<p>Here you can find a series of modules filled with tips and tricks to support you on your data management journey. Use what works and adapt as needed.  </p> <p>Below we present a simplified overview of the data life cycle within the broader research life cycle. Think of this as a roadmap to help navigate your own research journey. Some modules may be more relevant at specific times in the life cycle than others, but you will likely find it essential to consider data management at every step of the research journey.   </p>      The data life cycle, from design and planning through to access and re-use. All icons created by Freepik at Flaticon.     Module Overview Module 01 Top tips and tricks to make data management easy Module 02 The ethics and benefits of good data management practices Module 03 Hot, warm, and cold data storage Module 04 Helping eResearch and libraries staff help you Module 05 Data Management Plans in practice Module 06 Indigenous data sovereignty Module 07 The what, why and how of metadata management Module 08 Incorporating data management into daily practice Module 09 Developing data management culture in research teams Module 10 Working with local communities"},{"location":"modules/module01/","title":"Module 01 - Top tips and tricks to make data management easy","text":"<p>In this module we outline some tips and tricks that we have found handy for our own research. But it is important to note that every journey is different, with some potential detours! As such, your mileage with these tips may vary.  </p>"},{"location":"modules/module01/#taylor-and-atsushis-advice-for-emerging-researchers","title":"Taylor and Atsushi\u2019s advice for emerging researchers","text":"<p> <li>If you don\u2019t understand a workshop the first time around, it\u2019s ok to sign up and do it again.</li> <li>There is no such thing as a dumb question. In fact, someone else is probably wondering the same thing! You are more likely to get things wrong if you make assumptions without clarifying. Ask questions so you can get things right the first time!</li> </p> <p> <li>You can learn a lot from working alongside others so why not organise a 'hacky hour'? This is a casual drop-in meeting time for researchers using bioinformatic tools to come together to share solutions and collaborate on troubleshooting challenges. You will likely find that you will learn shortcuts, quick keys, and handy commands from watching other people work.</li> <li>We recommend you use programs that can make writing, editing, and running scripts easier, like RStudio or Visual Studio Code.</li> </p>"},{"location":"modules/module01/#darryls-advice-for-emerging-researchers","title":"Darryl\u2019s advice for emerging researchers","text":"<p> <li> Reach out to your institution's data management experts and support staff for assistance - ideally early in the research lifecycle.</li> <li> Avail yourself of the free and widely available research data management resources online. This Hub is a great starting point!</li> <li> Learn how to keep your documents and processes under version control (using git and similar tools), and make commits often.</li> <li> Give it a go. Start writing a data management plan before you start your research, and ask for help along the way. Practice makes perfect!</li> </p>"},{"location":"modules/module01/#professor-nepias-advice-for-research-team-leaders","title":"Professor Nepia's advice for research team leaders","text":"<p>Foster a positive data management culture in your group, including:</p> <p> <li> Develop clear documentation around on/offboarding procedures and daily management practices</li> <li> Make data management a standing item on the agenda for research team meetings</li> <li> Support your data management champion(s) in:     <ul><li> Overseeing the onboarding and identifying training needs for new members to ensure the implementation of consistent data management practices</li> <li> Operating as a conduit between the research team and eResearch and libraries staff</li> </ul></li> <li> Embed succession planning across the research team, especially for the data management champion</li> </p>"},{"location":"modules/module02/","title":"Module 02 - The ethics and benefits of good data management practices","text":"<p>Effective data management not only helps make you more efficient and your research more reproducible, it can also mitigate the ever-present risk of data misuse. Misuse can range anywhere in severity from accidentally sharing data without authorisation to cherry-picking of data and outright theft. </p> <p>The consequences of data misuse are infectious and can extend beyond an individual to the research group, collaborators, and their institutes in the form of serious legal implications, reputational risk, and negative impacts on career trajectories. On a broader level still, data misuse is harmful to the integrity of the research, science, and innovation sector, and has important social implications relating to public trust in science.  </p> <p>We're not intending to be dramatic by pointing out these consequences, or scare researchers into data management. Rather, we hope that by highlighting some of the potential risks and consequences, we can enable researchers to mitigate these by implementing conscientious and consistent data management practices. </p> <p>We recognise that there remains a gap between knowing and doing, in part due to the scarcity of ethical frameworks and clear guidance on what day-to-day data management could look like. Different groups will be positioned at different points on their data management journeys. </p> <p>While it is easy to envision the consequences of data misuse, what are the incentives to upholding good data management practices?</p> <ul> <li>Good data management minimises the risks of data misuse, loss, or theft, improves transparency, and ensures data management aligns with the FAIR and CARE Principles as appropriate for the data.</li> <li>Good data management benefits the researcher through increased efficiency and greater opportunities for and outcomes of collaborations, with flow-on effects that can help to accelerate career trajectories.  </li> <li>Good data management makes life easy!  </li> </ul> <p>We encourage researchers to view data management practices as behaviours intrinsic to the research process. A little data management often is a great way to start. </p>"},{"location":"modules/module03/","title":"Module 03 - Hot, warm, and cold data storage","text":"<p>When it comes to data storage, it can be easy to get lost in a sea of terms and acronyms. Which is better, SSD or HDD? Cloud or hybrid cloud? A cloud of what? Like many things in life, the answer to all of these questions is simple - It depends!  </p> <p>While storage hardware considerations can be tricky to navigate, it's worth investing time and energy in choosing which storage solutions you need early in the research lifecycle. This is because a sound data storage strategy is your first line of defence against data loss in the event of natural and/or human-derived disaster. In this Module, we\u2019ll briefly explore three classes of storage types: hot, warm and cold, and how storage type may inform data management strategies. Once you find which storage temperatures best suit your needs, we recommend talking to your eResearch support team to find which hardware solutions best fit the bill.  </p> <p>The differences between storage types have less to do with spice level or temperature and more to do with the speed of read and write access. The hotter the storage, the faster the speed of access. However, the need for speed comes at a cost... literally. The faster your read/write capability, the more expensive it is. When choosing hardware, striking a balance between the intended use and financial resource will go a long way in helping you identify the appropriate hardware. For example, you will want the fastest access possible for data analysis, and therefore the hottest storage option. For data that is accessed intermittently or stored in the long-term, colder options with slower access and lower costs will do the trick.  </p>      A comparison of factors associated with different data storage temperatures, from hot to cold.    <p>For consistency within research teams, it may be helpful to decide together which data/file types require which storage temperatures to maximise efficiency, maintain data security, and meet the needs specified in DMPs. Regardless of how hot or cold your storage is, it\u2019s important to make sure sufficient metadata (see Module 07) is collated alongside your data to support other users (including future you!) in navigating directories and understanding file contents.  </p>"},{"location":"modules/module03/#what-is-hot-storage","title":"What is hot storage?","text":"<p>In the case of hot storage, we generally mean storage for data that you're actively analysing that requires immediate read/write access. Data is generally stored locally to where it is being analysed. One example of appropriate hot storage use would be for data actively in use for genome alignment and variant discovery.</p> <p>As a general rule of thumb, hot storage should be considered a temporary home for data. This is because it is a relatively expensive resource that is best suited to holding data for active use, and so more focus is placed on performance. In an HPC environment where you want to squeeze out maximum performance, hot storage may not be backed up, as performance takes a hit during backing up, and \u2018quiet time\u2019 to do so is rare.  </p> <p>Taking all this into consideration, hot storage is not a good place for keeping your data in the long term - there may not be enough room and it is not safe. You should keep a master copy on a cooler form of storage where safety and integrity are ensured and only copy what you need onto the hot storage for your compute. As you generate important results, these should be moved from hot storage to a cooler storage option at the first opportunity.</p>"},{"location":"modules/module03/#what-is-warm-storage","title":"What is warm storage?","text":"<p>Next up is warm storage, which is best suited for data with intermittent access requirements. It is generally less expensive than drives used for hot storage. While access to data is slower, it is relatively immediate and is a good staging place for data that you use regularly. Analysis that does not require HPC can take place here, and this storage can usually be backed up. Data that you might consider putting on warm storage includes files that take a long time to generate and are likely to be reused, such as BAM alignment files used for variant discovery. </p> <p>A typical drive in a personal machine issued by an institute is warm. But note - although some institutes will issue faster drives, you\u2019ll notice these have low capacity and you will likely need to rely on a form of network or cloud storage to supplement it. Network storage at your institute is more warm (to you) than hot.  </p>"},{"location":"modules/module03/#what-is-cold-storage","title":"What is cold storage?","text":"<p>Finally, cold storage is largely for data that is rarely accessed or archived. For cold storage, the emphasis is placed on the most bang for your buck for capacity. With that being said, cold storage comes in many varieties depending on how much money you want to spend, the capacity you need and the retrieval time you are willing to accept.  </p> <p>While data in hot and warm storage is accessible immediately (in human terms), in the coldest storage access can take minutes, hours, or even days, depending on the size of the data, the technology involved and whether human intervention is needed. Cloud storage options like Dropbox and OneDrive are actually more towards the cold end of the thermometer, as data needs to be synchronised or downloaded/uploaded.</p> <p>In cold storage there should also be a great emphasis on data safety and integrity. The drive will usually be backed up, and there may be data integrity checks. This means that cold storage is an excellent place for storing master copies of raw data as a safety measure.  </p>"},{"location":"modules/module03/#the-strange-case-of-cloud-storage","title":"The strange case of cloud storage","text":"<p>Cloud storage systems (e.g., Dropbox, OneDrive, Google Drive, Amazon Web Services Cloud) are effectively cold if you want to use them on your machine. The primary interface for cloud storage is file transfer via a web browser, meaning it is not immediately available. Some services like Google Drive or Microsoft OneDrive use their associated cloud storage directly and if you use the associated web applications, it gives the appearance of warm storage. If you are only using this on a single machine, you effectively have a folder backed up in the cloud. But if you want to share a file or use the cloud as a common drive between machines, you may notice that data may not be immediately available. Sometimes how hot or cold a storage is depends on how remote it is to you or the application that uses it.</p>"},{"location":"modules/module04/","title":"Module 04 - Helping eResearch and libraries staff help you","text":"<p>Trying to navigate your institute's framework for data storage and management can be a lot like travelling through a new city when your phone battery has died. You may have a vague sense of the direction, but no idea of what you're looking for or how to get there. But never fear, eResearch and libraries staff are here to help!  </p> <p>There is one caveat to this: to best support research groups with their data management needs, eResearch and libraries staff require context and clarification to enable them to design and deliver appropriate solutions. The more information they have, the better the solutions they can provide. It may be helpful to consider the following list of needs and questions from an eResearch support person, both during conversations with eResearch and libraries staff, but also when developing DMPs. Not all of these questions can be answered at the outset of a project, but it can be helpful to keep them in mind as you progress along the data life cycle.</p> <p></p>"},{"location":"modules/module04/#what-eresearch-and-libraries-staff-want-from-researchers","title":"What eResearch and libraries staff want from researchers","text":"<p>While supporting researchers, eResearch teams have their own wants and needs that must be met to ensure they can deliver wrap-around data management solutions. Some of these include:</p> <p>      \ud83d\udcc2  Information on the research project <li>Who is responsible for the data? Who can make decisions about its management? This can be a person or a group, and preferably there is a clear chain of custody so the data is never orphaned inside the institution.</li> <li>How is the research funded? Research funders often require applicants to prepare and submit DMPs as part of their research funding application.</li> <li>Are there any allocated funds for research compute &amp; storage?</li> <li>What are the project timelines and deliverables so that I can forecast these needs for the future?</li> </p> <p>   \ud83d\udcc3  Information on the research data <li>I do not want researchers to put all their data in monolithic heaps. I want them to provide unique identification for each data set they want stored. All downstream data management solutions depend on this.</li> <li>What kind of protections are required for the data? Is it personal data, Indigenous data, commercial data or open data?</li> <li>Who can access the data within these protections? Are there any external collaborators that will require access to the data?</li> <li>How will the data be consumed? How do the researchers want to access the data within the protections that need to be met?</li> <li>What is the expected data volume? How will it grow over time?</li> <li>What should be done with the data once it has reached the end of the immediate research life cycle?</li> <li>Are there plans for the preservation and archiving of the datasets, and if so, which files, and for how long?</li> <li>Can or should data be deleted in the future?</li> <li>What outputs will your research will generate, and will this data have value to other researchers?</li> </p> <p>   \u2754  Information on support needs <li>What resources will you require to carry out your research? Will you need specific hardware, software, additional training or access to technical expertise?</li> </p>"},{"location":"modules/module05/","title":"Module 05 - Data Management Plans in practice","text":"<p>A data management plan (DMP), sometimes referred to as a data management and sharing plan, defines a framework for how researchers use and interact with data under their care. In this Module, we\u2019ll look to our Personas for examples of why DMPs are an essential research tool and provide some suggestions to springboard researchers looking to develop their first DMP. </p>"},{"location":"modules/module05/#the-newbie-tackling-a-new-project","title":"The newbie tackling a new project","text":"<p> Taylor is a fresh-eyed PhD student excited to be working on a new project for a culturally significant species. No previous work has been done, so Taylor will need to develop a DMP from scratch. Taylor will work closely with their supervisor, Professor Nepia, who holds established relationships with Indigenous research partners with cultural connections to the focal species. To clearly communicate the terms under which the data will be generated, used, and accessed by all parties they need to establish a DMP for this project.  </p> <p>  To co-design a DMP that is fit-for-purpose, Professor Nepia leverages her previous experience to balance institutional responsibilities, research objectives, and priorities of Indigenous research partners. For instance, the university has a mandate for researchers to provide DMPs, the project will generate a large amount of data from hundreds of samples collected at various locations, and Indigenous research partners' desire to maintain kaitiakitanga. Through conversations between Taylor, Professor Nepia, Indigenous research partners, and representatives from a national wildlife department, Taylor has identified institutional commitments, research requirements, and Indigenous needs around the data. They have collated these in a table so they can clearly understand their obligations.    </p>  What  When  Where  Who Project: whole genome resequencing of a lizard species, many individuals sampled from across the species range sequenced to moderate depth, a reference genome sequenced and assembled Start date: ASAP Processing &amp; storage: Institutional computation and storage resources Data custodian: Professor Nepia on behalf of Indigenous research partners during the research life cycle Metadata: project title, funding organisation, project ID, species, sample IDs, geographic location, collection date, details of ethics permits, Indigenous affiliations, primary contact details Project duration: 4 years DMP in development Different groups involved with data collection and generation: national wildlife department - long-term species monitoring, Taylor - sample collection with Indigenous community members, lab work, analysing data and preparing research outputs, sequencing facility  - producing raw DSI Data types: blood and/or tissue samples, digital sequence data, environmental data. Blood/tissue samples will be held on behalf of the Indigenous research partners at the university during the project. DSI to be generated within the next 12 months Agreement with local sequencing facility for data generation and secure transfer Decision-making is in partnership - Indigenous research partners, key representatives of national wildlife department, with context for decisions provided by Taylor and Professor Nepia File types to be generated: raw DSI (FASTQ files), genome assembly files, BAM alignment files, variant call files, spreadsheets, analysis results Sampling notes in hard copy (field notebooks) with key metadata transcribed into spreadsheets housed in institutional cold storage Potential for data reuse, but conditions for this yet to be determined Data protection requirements and potential data reuse are being actively discussed by decision-makers DSI volume to be generated: on the order of terabytes. Keeping Darryl appraised of data storage needs will help the eResearch team allocate appropriate resources to the project. <p>Professor Nepia and Taylor recognise this will be an iterative and collaborative process, requiring regular engagement with the community so all parties are briefed regularly on progress, and to continue conversations to ensure the resulting DMP will serve the intended purpose while being responsive to change. With this information in hand, Taylor and Professor Nepia are now equipped to begin work on developing a DMP that satisfies these needs. </p>"},{"location":"modules/module05/#the-experienced-data-manager","title":"The experienced data manager","text":"<p> Dr Sato is an old hand when it comes to operating under established DMPs. Although he finds data management an onerous part of the research process, he recognises its importance, and has developed skills to help him adhere to DMPs in his daily workflows. He understands that as a middle-man for diverse data sets, it is important that he familiarises himself with access and usage requirements.    </p> <p>In Dr Sato\u2019s case, leveraging datasets with different data management requirements is not uncommon. He relies on collaborators to provide a well-defined DMP alongside the data. He is tasked with the role of identifying the practical intersection between technical aspects such as data storage and computing needs, and governance as determined by existing DMPs. While Taylor and Professor Nepia are concerned with development of a DMP, Dr Sato has to adhere to DMPs that have been defined by collaborators. </p> <p>In his role, Dr Sato generates large quantities of intermediate analysis files, and typically hands off data to other collaborators once analysis is complete. He is less concerned with long-term storage requirements, and more with the here-and-now of these data sets. Similarly to Taylor, he has created a table of his data management concerns and considerations.</p>  Who  What  When  Where  Why  How Project: Climate change impacts on adaptation of fisheries stocks Secure data transfer required, with restricted data access Data generated at external institutions iteratively over past 5 years Very comprehensive metadata supplied by collaborators Computationally intensive so requires national HPC infrastructure Some data being reused for purposes other than that initially determined Collaborators leading the project are acting as data custodians and decision-makers for data management Atsushi intends to complete work on this project within the next 6 months DMP provided by collaborators - but this lacks information on whether some key files are available for reuse Supplied data and outputs to be deleted following delivery of results as per DMP Data supplied is BAM/CRAM alignment and variant call files including thousands of samples along with climate data, on the order of terabytes Analysed data to be returned to collaborators, supplied data to be deleted on completion Accessed on the national compute infrastructure via Atsushi's private project directory <p>Among these concerns, he observes a shortfall in one of these existing DMPs, that lacks guidance for the potential reuse of key intermediate files. While this small oversight is not the end of the world, he will need to discuss this with his collaborators, who may need to revise this DMP. </p>"},{"location":"modules/module05/#the-foundation-of-a-dmp","title":"The foundation of a DMP","text":"<p>By having done the background thinking and having discussions around data management for a proposed project you will be well prepared to develop a DMP. Some examples of what may be covered in a DMP include: </p> <ul> <li>Data types</li> <li>Data formats and standards</li> <li>Data roles and responsibilities</li> <li>Data dissemination</li> <li>Data sharing &amp; access</li> <li>Archiving &amp; persistence</li> </ul> <p>While some funding bodies or institutes may designate specific templates, these are likely to cover fairly similar aspects and can be readily adapted to suit. Considering the 5Ws (+H) for your project should help you to populate any template.</p>"},{"location":"modules/module05/#resources-for-developing-a-data-management-plan","title":"Resources for developing a Data Management Plan","text":"<p>DMPs are widely used across the research, science, and innovation sector. As such, there is no need to reinvent the wheel - leverage the wide array of available resources to help you get started! </p>"},{"location":"modules/module05/#online-data-management-resources","title":"Online data management resources","text":"<p>The Digital Curation Centre provides useful guides and advice to help you get started.</p> <p>MANTRA is a free, online non-assessed course with guidelines to help you understand and reflect on how to manage the digital data you collect throughout your research. It has been crafted for the use of post-graduate students, emerging researchers, and information professionals. It is freely available on the web for anyone to explore on their own. </p>"},{"location":"modules/module05/#online-resources-for-developing-data-management-plans","title":"Online resources for developing Data Management Plans","text":"<ul> <li> <p>Use a checklist to see if you need to create a DMP: https://www.dcc.ac.uk/guidance/how-guides</p> </li> <li> <p>Check out 10 simple rules for creating a good DMP for useful guidelines on what to include in DMPs. </p> </li> <li> <p>To create your own DMP, you can try out the Digital Curation Centre's Data Management Plan Tool, or the Data Stewardship Wizard, which is used Horizon Europe and other international funding bodies, and which incorporates version control.</p> </li> </ul>"},{"location":"modules/module05/#other-ways-to-learn-about-data-management-plans","title":"Other ways to learn about Data Management Plans","text":"<ul> <li> <p>Attend a course on Data Management at your local institute.</p> </li> <li> <p>Reach out to your institute's Data Librarian, Data Stewards, or Research Data Management teams for expert assistance and support.</p> </li> </ul>"},{"location":"modules/module06/","title":"Module 06 - Indigenous data sovereignty","text":"<p>There is no shortage of think-pieces that contextualise the FAIR and CARE Guiding Principles, and a growing number of empirical examples that facilitate Indigenous People\u2019s Rights in Data and Indigenous data sovereignty (e.g., Indigenous Peoples\u2019 Rights in Data: a contribution toward Indigenous Research Sovereignty). There are many ways these goals can be achieved. Here, we focus on helping researchers translate these principles into meaningful actions to empower Indigenous research partners.  </p>"},{"location":"modules/module06/#developing-relationships-with-indigenous-research-partners","title":"Developing relationships with Indigenous research partners","text":"<p>We encourage researchers to learn more about the global and local impacts of colonisation. In doing so, researchers will be able to better appreciate that Indigenous communities are operating against a backdrop of colonialism, and may be at different stages along the path to reconciliation. As such, it is important to recognise that Indigenous researchers and research partners may have limited capacity to engage with research projects that may be only one of many concerns that the community will be engaging with. In some cases, communities may have become disconnected from culturally significant species, sites, and knowledge. These factors may impact the ability of Indigenous communities to engage with research. Take care not to confuse a lack of capacity for engagement with a lack of interest in the research. In addition, not all Indigenous communities will have established frameworks for research engagement. It can be challenging to know where, and with whom, to start a conversation, but don\u2019t be discouraged. Leveraging existing networks is a good place to start.</p> <p>As with any professional relationship, identifying mutual goals and defining boundaries will be key for establishing an effective working environment. It is imperative to build relationships prior to any research journey. Being aware of the needs and aspirations of Indigenous research partners goes a long way towards developing mutually beneficial, trust-based relationships. Meeting community research partners where they are and in a culturally-safe setting facilitates open discussion, and will allow ample time and space for both parties to ask questions and address concerns, both at the inception of a project and regularly throughout the research life cycle. </p> <p>As biodiversity researchers, it is our responsibility to our Indigenous research partners to familiarise ourselves with the tools and infrastructures available to support their interests (e.g., access-controlled repositories, metadata inclusion and/or privacy, Traditional Knowledge and Biocultural Labels). Being able to present a range of the available data management options including storage, access, and use, and being knowledgeable about the ins and outs of each will be invaluable. By being adequately prepared and patient, we also reduce the workload (and the urgency) for our Indigenous research partners, who may be donating their time and expertise as a service to their community. Indeed, addressing that particular inequality through resource provisioning (i.e., funding as a contribution to recognise their time and expertise) may be one way in which researchers can support their Indigenous research partners.</p>"},{"location":"modules/module06/#publishing-and-reuse-of-restricted-access-data","title":"Publishing and reuse of restricted-access data","text":"<p>When working with culturally significant data sets, it is important to keep a flexible mindset. In doing so, we can develop practices that are ultimately responsive to specific community needs now and into the future. While it may be tempting to rely on existing precedents, there is no single 'best' data management strategy that will suit all situations. Rather, needs and aspirations will vary between Indigenous communities, research contexts, and through time and space.</p> <p>Data storage options may range from local (institute-based or Indigenous community-controlled), to national or international (cloud-based) servers. The Aotearoa Genomic Data Repository is one such national-level example. Details of the underlying principles and considerations incorporated into the development of this platform are found in Aotearoa genomic data repository: An \u0101huru m\u014dwai for taonga species sequencing data. Each storage option will likely offer different levels of data access, from closed (no access), restricted (password protected access available on application), to full open access. Using tools such as the Traditional Knowledge and Biocultural Labels can facilitate connections between Indigenous research communities and data, indicating how, when, and where data can be accessed and used (e.g., for commercial or non-commercial purposes, at specific times of year, or by specific groups of people), and appropriate channels for engagement. Having a good understanding of the available options to share with Indigenous research partners can facilitate those conversations. </p> <p>There appears to be a misconception that because many journals now require 'Data Accessibility' statements, that only open access data can be published. This is perhaps conflated with journal publications being open access themselves. While many journals indicate a preference for data to be publicly archived in established international repositories (e.g., NCBI, SRA), this may not limit the publication of data that is not open access. In recognition of the need to facilitate Indigenous data sovereignty, a growing number of journals are accepting various data access requirements as part of the publication process. As a result, researchers may want to keep an open mind when presenting data accessibility options for Indigenous research partners. Through conversations with our Indigenous research partners, we can find a point on the data access spectrum that satisfies multiple needs and aspirations, by being as open as possible, and as closed as necessary. </p> <p>Journal guidelines to authors may also help to indicate those journals that are more sympathetic to Indigenous data sovereignty needs. Note where journals make mention of data accessibility or benefit-sharing in line with the Convention on Biological Diversity  and Nagoya Protocol on Access and Benefit Sharing agreements, as this can be an indicator that the journal is more likely to be responsive to the needs of Indigenous partners where a limited data access model has been agreed on. If there is push-back from Editors around data accessibility, then that may be a red flag indicating that the journal\u2019s values are not well-aligned with those of your research team, and it may be best to submit your research elsewhere.</p>"},{"location":"modules/module06/#additional-resources","title":"Additional resources","text":"<p>For background on the Aotearoa New Zealand context that we operate within, we suggest looking to resources such as the work led by Te Mana Raraunga | M\u0101ori Data Sovereignty Network and a recent discussion paper led by Tahu Kukutai on M\u0101ori Data Sovereignty and Privacy, along with the guidelines laid out in Te K\u0101hui Raraunga | M\u0101ori Data Governance Model. There is also the M\u0101ori engagement framework for biodiversity genomics presented in Embedding indigenous principles in genomic research of culturally significant species: a conservation genomics case study, with an example of the implementation of these practices in Weaving place-based knowledge for culturally significant species in the age of genomics: Looking to the past to navigate the future. </p> <p>While these resources are framed around the Aotearoa New Zealand context, they draw from examples across Indigenous perspectives globally, such as Access and Management: Indigenous Perspectives on Genomic Data Sharing, Data governance for Native Nation Re-building, Rights, interests and expectations: Indigenous perspectives on unrestricted access to genomic data, and Indigenous peoples and local communities as partners in the sequencing of global eukaryotic biodiversity, among many others.</p>"},{"location":"modules/module07/","title":"Module 07 - The what, why, and how of metadata management","text":""},{"location":"modules/module07/#what-is-metadata","title":"What is metadata?","text":"<p>Metadata in its broadest form is 'the data about the data'. Metadata provides the spatio-temporal context for digital sequence information (DSI), and may be vital for interpreting and contextualising results. For biodiversity genomic data, the core metadata is defined by community standards such as the Genomics Standards Consortium and Biodiversity Information Standards, including the MIGS and MIxS specifications. </p>      An overview of the minimum metadata for genomic data.    <p>For processed data, metadata will also include information such as the software, software versions, and parameters used. Additional metadata may include associated keywords, downstream publications, funding sources, and data access and licensing details. To get an idea of metadata beyond the minimum, check out the Darwin Core terms for an extensive list. </p>"},{"location":"modules/module07/#why-should-we-be-collecting-and-managing-metadata","title":"Why should we be collecting and managing metadata?","text":"<p>Metadata should be recorded and managed alongside DSI to ensure that results produced using these data can be placed into the appropriate context. Collation and stewardship of metadata is also essential to ensure that data meet the requirements of the FAIR Principles, and so facilitating the traceability and future use of data. Not only that, but metadata describing the spatiotemporal context for data enables the connection of DSI to associated Indigenous communities, facilitating benefit-sharing into the future as described by the CARE Principles for Indigenous Data Sovereignty.</p>"},{"location":"modules/module07/#how-can-we-best-manage-metadata","title":"How can we best manage metadata?","text":"<p>At its core, metadata collation and stewardship all come down to the need for thorough and consistent record-taking and record-keeping throughout the research life cycle, from sample collection through to dissemination of results. Starting early will save you from headaches down the track! </p> <p>Portals such as the Genomic Observatories MetaDatabase (GEOME) and the Collaborative Open Plant Omics (COPO) allow users to generate template to populate with metadata associated with DSI. By using existing templates, users can ensure that metadata is recorded in ways that are consistent with biodiversity genomics community standards.</p> <p>Tools such as version control, software containers, and workflow management systems can be extremely helpful in tracking metadata during data processing and analysis. These tools can be particularly useful when shared across the research group, along with guidelines for directory structure and file naming conventions, ensuring team-wide consistency. For more on these tools, see Module 08.</p>"},{"location":"modules/module07/#further-reading","title":"Further reading","text":"<ul> <li>Crandall, E. D. et al. (2023). Importance of timely metadata curation to the global surveillance of genetic diversity. Conservation Biology, 00(e14061). https://doi.org/10.1111/cobi.14061</li> <li>Field, D., et al. (2008). The minimum information about a genome sequence (MIGS) specification. Nature Biotechnology, 26(5), Article 5. https://doi.org/10.1038/nbt1360</li> <li>Yilmaz, et al. (2011). Minimum information about a marker gene sequence (MIMARKS) and minimum information about any (x) sequence (MIxS) specifications. Nature Biotechnology, 29(5), Article 5. https://doi.org/10.1038/nbt.1823</li> </ul>"},{"location":"modules/module08/","title":"Module 08 - Incorporating data management into daily practice","text":"<p>Knowing where to start can be one of the hardest parts of the data management journey, but getting good practices in place early will save you from headaches down the track. There is a wealth of existing information on these and other important concepts for the research lifecycle, with this Module acting as a 'quick start' guide, giving a brief overview of important considerations such as directory structure and file naming conventions, structuring data sets in a tidy manner, the use of version control, and workflow management. </p> <p>Beyond this Module, we recommend you investigate your institute's resources, as they may provide specific guidelines that meet institutional criteria. The Carpentries provide workshops and extensive documentation across a wide range of subject areas that can help you get started. We also recommend you familiarise yourself with the fundamental principles of tidy data early in your research journey, setting you up for long-term success. </p> <p>Whatever your approach, we recommend consistency above all else, in both the structuring of your data sets and work spaces, but also in your records. Maintaining comprehensive and consistent notes across all aspects of the research, from proposed research questions, existing scholarship, involvement of collaborators, data collection and generation procedures, and analysis (regardless of whether it was successful) will not only ensure reproducibility, but make your research papers faster and easier to write!  </p>"},{"location":"modules/module08/#tidy-data","title":"Tidy data","text":"<p>We recommend researchers get familiar with tidy data concepts prior to data collection where possible - though it's never too late! The three primary principles for structuring data sets tidily are:</p> <ul> <li>variables are contained in columns </li> <li>observations are contained in rows </li> <li>values are contained in cells </li> </ul> <p>Maintaining this structure allows data to be extracted, manipulated and analysed in a straightforward and consistent manner, saving you (or your collaborators) lots of time down the track!</p> <p>There are plenty of existing resources to help you wrangle your data into tidy formats, and especially for analysis in the R statistical environment. As a starting point, we recommend taking a read of Tidy Data, or exploring the examples and use cases in the R for Data Science introduction to Tidy Data. With this knowledge in hand, you'll be ready to create tidy spreadsheets, untangle messy ones, and use tools like the Tidyverse R package to ensure consistency across data sets.</p>"},{"location":"modules/module08/#genomic-data-management-fundamentals","title":"Genomic data management fundamentals","text":"<p>As an emerging biodiversity genomic researcher, the initial question you will have when you receive your first batch of genomic data is likely to be: What do I do with this? Your first step should always be to ensure that you keep an untouched backup copy of the raw data in cold storage. Metadata should be stored alongside the raw data (for example, in README files).</p> <p>Validating data transfer</p> <p>Whenever you transfer data, you will want to validate it, to ensure that the transfer completed with no errors and the files are intact. Checksums are a key validation tool. A checksum for a given file will always be the same no matter whether the file is moved or copied.</p> <p>script</p> <p>To generate a checksum for a raw compressed FASTQ file in your local directory:</p> <p><pre><code>  md5sum raw-data.fastq.gz &gt; raw-data.md5\n</code></pre> If you are on a Mac, replace the <code>md5sum</code> command with <code>md5</code>.</p> <p>To generate checksums for multiple FASTQ files:</p> <p><pre><code>  md5sum ./*.fastq.gz &gt; md5sums.txt\n</code></pre> The output text file will contain a list of the checksums for each of the compressed FASTQ files in the directory. The checksum file produced will look something like this, where the alphanumeric code is the checksum hash value:</p> <p><pre><code>  c6779ec2960296ed9a04f08d67f64422 ./raw-data-1.fastq.gz\n  002c33835b3921d92d8074f3b392ef65 ./raw-data-2.fastq.gz\n</code></pre> Then to validate the transferred file, copy the output checksum file to the transferred location, and perform the check:</p> <p><pre><code>  cp ./md5sums.txt /final-destination/\n  md5sum -c file.md5\n</code></pre> Each validated checksum will display <code>OK</code>, while a mismatched checksum will display <code>FAILED</code>. If you get a <code>FAILED</code> file, you will need to redo the file transfer and re-validate.</p>"},{"location":"modules/module08/#structuring-directories","title":"Structuring directories","text":"<p>With that done, you next want to move the data to your analysis space, and set up your directory (folder) structure. Having clearly structured directories keeps things tidy, and ensures that you can always tell where you are up to in your analysis pipeline. It is very likely that the first thing you want to check will be the quality of your raw data, so here we present an example directory structure suitable for that.</p> <pre><code>  .\n  |--- first-sequencing-project/\n  |   |--- raw-data/\n  |       |--- 2023-01-30-sequencing.fastq.gz\n  |   |--- scripts/\n  |       |--- 01-fastqc.sh\n  |   |--- outputs/ \n  |       |--- 01-fastqc/\n</code></pre> <p>Here you can see the top level directory <code>first-sequencing-project/</code> will contain everything to do with this project all in one place. Within this project directory there are three subdirectories: <code>raw-data/</code>, <code>scripts/</code>, and <code>outputs/</code>. By using simple, clear naming, the directory structure should be self-explanatory. </p> <p>Our raw data, in the form of a compressed FASTQ file, sits in the <code>raw-data/</code> directory. Scripts for processing the data, like the <code>01-fastqc.sh</code> bash script are all kept in one place. Using a numbering system for scripts and their associated output directories (like the <code>01-fastqc/</code> subdirectory within the <code>outputs/</code> directory) is helpful to keep track of the steps in the analysis pipeline. You can learn more about file naming conventions through MANTRA's 'Organising Data' research data management training unit.</p> <p>The <code>01-fastqc.sh</code> script that will be used to run FastQC to check sequencing quality should direct outputs to the <code>./first-sequencing-project/outputs/01-fastqc/</code> directory.</p> <p>From here, it will be relatively straightforward to build up an analysis pipeline from the <code>scripts/</code> directory, creating additional numbered subdirectories in <code>outputs/</code> for each associated set of output files produced. What other directories do you think you may need to create during later steps in the research life cycle?</p>"},{"location":"modules/module08/#version-control","title":"Version control","text":"<p>Version control is managing and tracking changes to documents. In the biodiversity genomics space, this will most commonly be used for keeping track of changes in analysis code and software development. It can also be used in research more generally for keeping track of changes to other documents such as manuscript drafts. </p> <p>For the latter, Microsoft Word and Google Docs include the facility to manage document versions. For coding purposes, the version control system Git will be an essential tool. While Git handles the version control, and associated cloud-based repositories associated such as GitHub makes sharing code with collabotors and colleagues very straightforward. These tools are widely used and well-documented, with plenty of support available to help new users upskill, for example through the GitHub 'Getting Started' pages. As these tools are widely used, there may also be local opportunities for institutional training and community support. </p>"},{"location":"modules/module09/","title":"Module 09 - Developing data management culture in research teams","text":"<p>It is vital to ensure the continuity of data management throughout the research life cycle. Data management is most effective when pursued as a team, with a consistent and cohesive long-term plan and some division of labour. A little effort early in the process can go a long way! Here we highlight two strategies to support research teams in achieving their data management aspirations. </p>"},{"location":"modules/module09/#documenting-data-management-guidelines-for-research-teams","title":"Documenting data management guidelines for research teams","text":"<p>We recommend that research teams develop clear documentation around on- and off-boarding procedures and daily data management practices. This will streamline the process of joining the team, provide guidance on the options for and constraints around data transfer, storage, and access. This also paves a clear pathway for ongoing access to data, or the packaging of data and metadata for long-term storage upon departure.</p> <p>Documentation of team guidelines can be hugely beneficial, both for the team leader in setting out expectations, and for members in understanding their obligations. Such guidelines are best co-developed by the team, with team members bringing the knowledge of the day-to-day minutiae required to meet the expectations set out by the team leader, while leaders can provide the deeper understanding of the structural and institutional limitations the team are working within. Further, to ensure balance within the team, it is important for all members to recognise that these expectations can be bi-directional. Not only does the team leader have expectations for the conduct and contributions of team members, but team members also will have expectations for their team leader. By clearly documenting these expectations, open conversations can be had at an early stage in the development of these relationships to guide interpersonal interactions among the research team.</p> <p>We do not intend to dictate what these relationships and interactions should look like, but merely highlight some aspects that research teams may wish to address and clarify in a research team strategy or other documentation, and specifically those aspects pertaining to data management. Clarity around expectations will be key in developing unified strategies, and emphasis can be made that data management is a responsibility of all team members. Daily data management practices can be described through a series of 'How To' guides. Topics for these 'How To' guides may include:</p> <ul> <li>tracking samples and managing inventories</li> <li>recording and maintaining metadata</li> <li>data decision-making processes (including access to and use of relevant data storage options across the research life cycle)</li> <li>developing and managing DMPs</li> <li>data sharing consistent with DMPs</li> <li>documenting analysis and using version control </li> <li>maintaining an up-to-date list of key people within the team and institute.</li> </ul> <p>These guidelines can be documented in a research team manual that clearly lays out on- and off-boarding processes, bi-directional expectations for interpersonal relationships, relevant ethical considerations and expectations, and any institutional requirements that may arise across the research life cycle. Some examples of these include, but are not limited to completing student-supervisor agreements, project proposals, human or animal ethics applications, and funding applications to support research or conference travel. </p>"},{"location":"modules/module09/#implementing-a-self-reflective-retrospective-following-project-completion","title":"Implementing a self-reflective retrospective following project completion","text":"<p>Self-reflective retrospectives are commonly used as part of agile meeting practices. A self-reflective retrospective process can be used following project completion to help identify which aspects went according to plan, where needs changed over time, and where limitations or challenges occurred due to institutional or infrastructure constraints. An example format could be:</p> <ol> <li>List 3 things that worked well when developing and/or actioning the project\u2019s DMP.</li> <li>List 3 things that created limitations and challenges when developing and/or actioning the project\u2019s DMP.</li> <li>List 3 things you might do differently next time to improve the process.</li> </ol> <p>The team can then come together to discuss, or the project leader can collate the feedback from these self-reflective retrospectives to identify where there are opportunities for improving processes.</p>"},{"location":"modules/module09/#establishing-a-research-data-management-culture-in-your-team","title":"Establishing a research data management culture in your team","text":"<p>To ensure consistency despite the potential for frequent turnover within the team, we suggest that research teams establish a data management champion to oversee the onboarding and training of new members and ensure the implementation of consistent data management practices across the research team. While anyone can take on this transferable role, a data management champion will ideally have a mid- to long-term position within the research team, hold a deep understanding of the unique characteristics of each research project, and have the necessary level of autonomy to operate independently as a leader in this role. Succession planning for this role will be essential to ensure consistency and continuity. </p> <p>This person can also operate as a conduit between the research team and eResearch and libraries staff, and so excellent people skills will be advantageous. By engaging regularly and often with their institute\u2019s support structures, they can ensure that eResearch and libraries staff are kept up to date with the changing needs of the team, and ensure access to the latest services and support. </p>"},{"location":"modules/module09/#navigating-conflicting-perspectives","title":"Navigating conflicting perspectives","text":"<p>Navigating high risk, high consequence (whether perceived or real) situations is stressful and can place a significant strain on working relationships. This is compounded in situations with imbalanced power dynamics, which can have particularly severe consequences for those holding less power (e.g., early career researchers (ECRs)). </p> <p>Below we outline a hypothetical scenario between Taylor and a fellow PhD student, Yana, that demonstrates some of the challenges that may arise due to conflicting perspectives around data management, followed by two dichotomous outcomes. This hypothetical scenario does not seek to address all issues relating to interpersonal relationships and conflict. We acknowledge that individuals in such situations experience unique and complex challenges, requiring tailored problem-solving. </p> <p>Taylor and Yana met at a conference after Yana saw Taylor present on their research which used similar methods to Yana\u2019s project, and included discussion of their process of engagement with Indigenous research partners. Despite being based at different institutions, they have a lot in common, and have become good friends. However, they are experiencing different research cultures in their teams. </p> <p>The research culture in Yana\u2019s team is competitive but friendly, with other students addressing different questions within the same system. The Research Team Leader (RTL) is highly motivated to publish, and places a great emphasis on rapid outputs, especially publications. Beyond dissemination to the wider scientific community, he does not consider science communication with the wider public a priority for the research team. Yana is excited to be part of such a fast-moving research team, but has recently become concerned about potential Indigenous data sovereignty needs for data generated during their PhD. The RTL has said that their focal species is not culturally significant. However, Yana has learnt that a number of samples were collected from several sites on land of cultural importance to an Indigenous group, and that there has been no engagement or consultation with the Indigenous community to date. Through ongoing conversations with Taylor, Yana is now questioning the research practices of her RTL and how they may impact the wider team, especially because a lot of the samples she is using are shared across multiple projects.</p> <p></p> <p> Yana: Hey Taylor! I\u2019m struggling with something that I\u2019ve been wanting to talk to you about for a while now. Have you got time to talk?   </p> <p> Taylor: Sure! How can I help?   </p> <p>Yana: I\u2019ve tried to have a conversation with my RTL about Indigenous engagement related to some of the samples that I\u2019m using in my thesis that were collected at several culturally significant sites. It did not go well. He basically encouraged me not to get distracted from the research.  <p> Taylor: I\u2019m sorry to hear that friend. It sounds like it was a hard conversation to have.   </p></p> <p>Yana:  I would like to engage with the local Indigenous community about our work and find out if they have data management needs for these samples. But I\u2019m worried my RTL thinks I am making trouble. I realise that engagement takes time, and I don\u2019t want to hold up the whole team.  <p> Taylor: That\u2019s such a hard position to be in. I know your team puts a lot of their focus on publications, so the pressure is real. But, ultimately, something I\u2019ve learned from Prof Nepia is that it\u2019s the RTL\u2019s role to lead Indigenous engagement. Have you shared your concerns with the wider team?   </p></p> <p>Yana: No, it\u2019s never come up. But I could try to start a conversation and see what they think.  <p> Taylor: Definitely, you may be surprised - it\u2019s possible that others share your concerns, but felt hesitant to speak up.   </p></p> <p>Yana: I hadn\u2019t thought of it that way. Thanks Taylor!</p>"},{"location":"modules/module09/#outcome-a","title":"Outcome A","text":"<p>Following her conversation with Taylor, Yana learned that members of her research team shared many of the same concerns but were similarly intimidated by the idea of raising the issue with their RTL. With support and encouragement from the team, Yana raised this topic for discussion during a team meeting. The RTL was surprised to learn of the team\u2019s concerns, as he was unfamiliar with the developing awareness within the field of biodiversity genomics of the need to engage with Indigenous communities. He was grateful to have these developments raised by the team. He is now learning about Indigenous data sovereignty and the CARE Guiding Principles, and gaining support from his academic and professional colleagues with experience working with Indigenous communities.</p>"},{"location":"modules/module09/#outcome-b","title":"Outcome B","text":"<p>Following her conversation with Taylor, Yana\u2019s conversations with her research team do not go well. Although some share her concerns, none felt comfortable discussing them with the RTL. Unsure of what to do next, Yana goes back to Taylor.</p> <p> <p> Yana: I talked to my teammates, but no-one feels comfortable trying to approach our RTL with me. I tried to speak to my RTL about my concerns again, but he got frustrated with me. I don\u2019t know what to do next.   </p></p> <p> Taylor: Would you like me to reach out to my Supervisor, Professor Nepia, for some advice?   </p> <p>Yana: Yeah! I think that would be great.</p> <p>Professor Nepia encourages Yana to seek support at her institution. For example, at the departmental level, she could reach out to a trusted academic for confidential advice, or seek support from a graduate advisor on how to approach these conversations with her RTL. Beyond her department, Yana could reach out to the graduate school, or the graduate students' association. Dedicated support services like these are best equipped to provide institution-specific advice and support. Professor Nepia is keen to hear how it goes, and offers to provide additional advice if needed. </p> <p>Both outcomes rely on ECRs having access to a supportive research environment within their teams, departments and institutions. </p>"},{"location":"modules/module10/","title":"Module 10 - Working with local communities","text":"<p>This page is currently under construction. Come back soon.</p>"},{"location":"personas/","title":"Personas overview","text":"<p>Here we describe four fictional user-experience personas and their associated data management needs. These personas cover a diversity of career stages and roles within the research ecosystem, and are loosely based on our personal data management journeys. We use these to highlight some of the key questions and challenges associated with biodiversity genomic data management. We hope that you will find aspects of these personas relatable. To gain a broad understanding of the various perspectives, we recommend taking a look at all four personas.</p> <p>Persona 1 - A student new to biodiversity genomics </p> <p>Persona 2 - An early career researcher working collaboratively</p> <p>Persona 3 - A biodiversity genomics research team leader</p> <p>Persona 4 - An eResearch staff member</p> <p></p>"},{"location":"personas/persona1/","title":"Persona 1","text":""},{"location":"personas/persona1/#phd-student-taylor-smith","title":"PhD student Taylor Smith","text":"<p>New PhD student Taylor Smith has started a research project that will use genomic data to inform conservation management for a culturally significant species. Their project involves data collection and generation, analysis using the local compute infrastructure provided by their institute, and dissemination of results to end-users including conservation practitioners and local communities. They will be operating under a DMP adapted from the template used across their research team, and they have access to internal training and external support structures. </p> <p>Their research team, led by Professor Nepia, is in the process of developing a lab manual that includes daily data management processes, along with onboarding and exiting procedures. Taylor is grateful for the supportive research environment, as they feel comfortable asking questions and sharing thoughts to help develop these processes. While their data is yet to be generated, being involved in these processes ensures they have a clear understanding of what will be involved in managing their data. </p> <p>Taylor\u2019s main concerns are in ensuring their data management practices facilitate Indigenous data sovereignty and uphold the FAIR and CARE Guiding Principles during the active life-span of the project. As the project has a defined end-date, they also want to ensure that there is a framework in place to maintain these requirements into the future. Communication around data management is primarily with Professor Nepia, who is maintaining long-term trust-based relationships with research partners, with additional support from their wider research team. </p> <p></p> <p>Mouse-over for definitions: DMP, HPC, IDSov, VM. See the Glossary for full definitions. </p>"},{"location":"personas/persona1/#taylors-key-questions-in-their-data-management-journey","title":"Taylor\u2019s key questions in their data management journey","text":"Question Associated module providing solutions Why is data management important? The ethics and benefits of good data management practices  Module 02 What are some key things I should know as I begin my data management journey? Top tips and tricks to make data management easy  Module 01 How can I enable Indigenous data sovereignty in my data management practices? Indigenous data sovereignty  Module 06 What is metadata, and how should I manage it? The what, why and how of metadata  Module 07 How can I structure directories for raw data and analysis? Incorporating data management into daily practice  Module 08 <p><p> Persona 2 </p></p>"},{"location":"personas/persona2/","title":"Persona 2","text":""},{"location":"personas/persona2/#research-fellow-dr-atsushi-sato","title":"Research fellow Dr Atsushi Sato","text":"<p>Dr Atsushi Sato is a postdoctoral research fellow at a national research institute, and contributes to several large international biodiversity genomics collaborations. These projects vary in scale, longevity, and data management requirements. Although he has some input in research planning and dissemination of results, his primary focus is on the analysis of large data sets, and specifically in incorporating environmental and climate data alongside genomic data. To do this, he relies on comprehensive and consistent metadata that sits alongside each data set. Each project Dr Sato is involved with has its own established data management plan (DMP), so he must take care to ensure that the workflows he uses for each project align with the respective DMPs. </p> <p>He is experienced in biodiversity genomics, and is able to clearly describe his data management needs to the eResearch support team at his research institute. These needs predominantly relate to short- to mid-term storage and access, as the long-term storage of most of the data sets Dr Sato works with is the responsibility of researchers at other institutes. Dr Sato also seeks support from the eResearch team that deliver the national high-performance computing (HPC) infrastructure, where he can harness multithreading and parallel-processing for analysing large data sets. </p> <p>Although Dr Sato\u2019s skills are in high demand, he has been persistently employed on precarious short-term contracts. He finds this stressful, and is constantly looking for new opportunities that may lead towards his goal of attaining a permanent research position. These concerns impact his research priorities, as he perceives trade-offs between time spent on data management versus that spent on data analysis that can contribute towards his publication record. From Dr Sato\u2019s perspective, data management is an onerous task.</p> <p></p> <p>Mouse-over for definitions: DMP, HPC, GPU. See the Glossary for full definitions. </p>"},{"location":"personas/persona2/#dr-satos-key-questions-in-his-data-management-journey","title":"Dr Sato\u2019s key questions in his data management journey","text":"Question Associated module providing solutions How can I efficiently keep on top of necessary data management? Incorporating data management into daily practice  Module 08 How do I ensure interoperability across large genomic and environmental data sets? The what, why, and how of metadata management  Module 07 How can I get help with access to analysis and storage resources? Helping eResearch and libraries staff help you  Module 04 <p><p> Persona 3 </p></p>"},{"location":"personas/persona3/","title":"Persona 3","text":""},{"location":"personas/persona3/#research-group-leader-professor-tehara-nepia","title":"Research group leader Professor Tehara Nepia","text":"<p>Professor Tehara Nepia is a principal investigator at a university overseeing a conservation genomics research team including postgraduate students (including Taylor), postdoctoral researchers, and research associates. Her focus is on designing, facilitating, and disseminating research, and providing a supportive environment that produces highly-skilled emerging researchers well-equipped to contribute to the research, science, and innovation sector. Professor Nepia also places strong emphasis on building and maintaining trusted relationships with research partners, collaborators (including Dr Sato, and end-users. A substantial part of her role includes seeking and managing funding and resources (including computing and data storage) for the research team. </p> <p>As the volume of data generated by Professor Nepia\u2019s research team is continually expanding, there is a growing need to ensure a smooth transition of data (including metadata) between members of her team. While Professor Nepia has a  responsibility to uphold institutional requirements around data management, she is also committed to embedding data management practices that facilitate Indigenous data sovereignty and uphold the FAIR and CARE Guiding Principles. She is working towards a DMP template for use across all her research team's projects. To achieve this, Professor Nepia encourages open two-way communication with her research team to gain their perspectives of the needs and challenges associated with data management. She relies upon her research team to adhere to the DMPs, to support and encourage each other to do this, and to seek strategic advice from her when needed. Beyond the DMPs, Professor Nepia and her team co-develop research team guidelines that include data management processes to streamline team on/offboarding, allowing new members to quickly get up to speed, and providing clear expectations of data management for those departing. </p> <p>To ensure workflows are aligned with best practice, she also engages with colleagues in similar situations nationally and internationally, including her disciplinary research community. Keeping abreast of evolving best practices in the research community and updating the research team's DMP accordingly is an added pressure on Professor Nepia\u2019s limited time; she never feels completely up-to-date with the latest developments but understands she must be the one in the research team to lead data management practices even if she is only able to support \u2018good\u2019 versus \u2018best\u2019 practice. </p> <p>To help with this burden, Professor Nepia prioritises building strong relationships with local eResearch and libraries staff (including Darryl that are based on transparent, timely, bi-directional communication. Through knowledge-sharing, eResearch and libraries staff help her to understand local data management capacity and constraints, and gain the necessary understanding of the project-specific nuances that enable delivery of wrap-around solutions that support the needs of the research team now and into the future. </p> <p></p> <p>Mouse-over for definitions: DMP. See the Glossary for full definitions. </p>"},{"location":"personas/persona3/#professor-nepias-key-questions-in-her-data-management-journey","title":"Professor Nepia\u2019s key questions in her data management journey","text":"Question Associated module providing solutions Where can I go to get support in understanding data storage options? Hot, warm, and cold data storage  Module 03  Helping eResearch and libraries staff help you  Module 04 Does my research team require bespoke data management tools? Data Management Plans in practice  Module 05 How can I implement and maintain a consistent, cohesive data management strategy for my research team? Data Management Plans in practice  Module 05  Developing data management culture in research teams  Module 09 How can I support my research team in upholding both the FAIR and CARE Guiding Principles? Indigenous data sovereignty  Module 06 <p><p> Persona 4 </p></p>"},{"location":"personas/persona4/","title":"Persona 4","text":""},{"location":"personas/persona4/#institutional-eresearch-manager-darryl-baker","title":"Institutional eResearch Manager Darryl Baker","text":"<p>Darryl Baker is an eResearch Manager at an academic institution, and provides eResearch support to numerous research projects across all disciplines and departments, including providing advice and services relating to computing and data storage facilities. Darryl keeps up to date with research-focused technologies and mentors researchers on the use of research systems. Darryl manages the resource that is the institutional computing and storage facilities allocated to research. </p> <p>In the last four years the storage facility of the institution has reached peak capacity, requiring careful management of its resources. Darryl seeks budget approval to expand the current on-premise storage facility. Based on quotes provided by vendors, purchasing storage infrastructure proves to be expensive. Furthermore, this would be a short-term solution as the institution\u2019s research data is predicted to exceed the storage limit within five years.</p> <p>Recently, Professor Nepia contacted Darryl for eResearch services and support for her conservation genomics research team. Professor Nepia\u2019s team works across multiple research projects, producing a growing amount of data over the last 10 years. Darryl meets with one of Professor Nepia\u2019s research students, Taylor, to understand the eResearch needs of an upcoming project about a new species of lizards that is culturally significant to local Indigenous Peoples. In a face-to-face meeting, he gathers information about the data being produced. Early indications are that this project will generate vast amounts of data and function under a DMP.  </p> <p>Darryl wishes to understand the project-specific needs in order to advise on appropriate storage and computing solutions that will facilitate Indigenous data sovereignty and uphold the FAIR and CARE Guiding Principles. Darryl clearly understands the constraints arising from the institutional infrastructure, and the responsibilities of the researcher under national and institutional legislation.</p> <p>Through conversations with researchers and research teams, Darryl can gain a clear vision of what they are trying to achieve. At the same time, Darryl holds the awareness of the constraints arising from institutional infrastructure, and the responsibilities of the researcher under national and institutional legislation. </p> <p></p> <p>Mouse-over for definitions: DMP. See the Glossary for full definitions. </p>"},{"location":"personas/persona4/#darryls-key-questions-to-support-research-groups-in-their-data-management-journeys","title":"Darryl\u2019s key questions to support research groups in their data management journeys","text":"Question Associated module providing solutions What are the needs of the researcher, research team, and of their data? Helping eResearch and libraries staff help you  Module 04 Is there a DMP for this research, and what does it contain? Data Management Plans in practice  Module 05 How is the data intended to be stored, and for how long? Hot, warm, and cold data storage  Module 03 Is the data properly labelled, and is there associated metadata? The what, why and how of metadata  Module 07 Are there any additional considerations around the data? Indigenous data sovereignty  Module 06"},{"location":"teaching-resources/","title":"Teaching Resources overview","text":"<p>Here you can download slides that contain image files and content found in this Hub for use in teaching. Right-click the image and select 'save link as' to download the complete Powerpoint slides.</p> <p>We request that if you use any of the slides, figures, or illustrations provided here, that you include a link to the Biodiversity Genomic Data Management Hub at https://genomicsaotearoa.github.io/data-management-resources/.</p> <p> </p> <p> </p>"}]}